{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0c9d23",
   "metadata": {},
   "source": [
    "# UFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# features_list = []\n",
    "# for i in range(1, 92, 10):\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     y = label_encoder.fit_transform(y_train)\n",
    "#     y_t = label_encoder.fit_transform(y_test)\n",
    "\n",
    "#     best_select = SelectKBest(score_func=f_regression, k=i)\n",
    "#     best_select.fit(X_train, y)\n",
    "\n",
    "#     best_features = best_select.get_support(indices=True)\n",
    "#     features = X_train.columns[best_features]\n",
    "#     features_list.append(features)\n",
    "#     new_train = X_train[features]\n",
    "#     new_test = X_test[features]\n",
    "\n",
    "#     lr = LogisticRegression(max_iter=10000)\n",
    "#     lr.fit(new_train, y)\n",
    "#     y_pred_train = lr.predict(new_train)\n",
    "#     y_pred = lr.predict(new_test)\n",
    "\n",
    "#     accuracy_train.append(accuracy_score(y, y_pred_train))\n",
    "#     accuracy_test.append(accuracy_score(y_t, y_pred))\n",
    "\n",
    "# print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "# print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "# print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "# plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "# plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "# plt.xlabel(\"Number of features to select\")\n",
    "# plt.ylabel(\"Accuracy(%)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dd966",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba974ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "# accuracy_train = []\n",
    "# accuracy_test = []\n",
    "# features_list = []\n",
    "# for i in range(1, 92, 10):\n",
    "#     lr = LogisticRegression(max_iter=10000)\n",
    "#     rfe = RFE(lr, n_features_to_select=i)\n",
    "#     fit = rfe.fit(X_train, y_train)\n",
    "#     best_features = X_train.columns[fit.support_]\n",
    "#     features_list.append(best_features)\n",
    "#     final_model = LogisticRegression(max_iter=10000).fit(X_train[best_features], y_train)\n",
    "#     y_pred_train = final_model.predict(X_train[best_features])\n",
    "#     y_pred = final_model.predict(X_test[best_features])\n",
    "    \n",
    "#     accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "#     accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "# print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "# print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "# plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "# plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "# plt.xlabel(\"Number of features to select\")\n",
    "# plt.ylabel(\"Accuracy(%)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
