{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, log_loss\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23469942",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Mushroom_datasets/mushroom_train.csv')\n",
    "data_test = pd.read_csv('Mushroom_datasets/mushroom_test.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9af22",
   "metadata": {},
   "source": [
    "# Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ab325",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_train.shape[0]\n",
    "N1 = data_train[data_train['class']=='p'].shape[0]\n",
    "N2 = data_train[data_train['class']=='e'].shape[0]\n",
    "N_test = data_test['class'].shape[0]\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(N_test):\n",
    "    if random.random() < N1/N:\n",
    "        y_pred.append('p')\n",
    "    else:\n",
    "        y_pred.append('e')\n",
    "\n",
    "acc = 0\n",
    "for i in range(N_test):\n",
    "    if y_pred[i] == data_test['class'][i]:\n",
    "        acc+=1\n",
    "        \n",
    "print(\"Accuracy of test dataset is\", acc*100/N_test, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a55695",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = f1_score(data_test['class'], y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51354821",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(data_test['class'], y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual P', 'Actual E'], columns=['Predicted P', 'Predicted E'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca1e4a",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season']\n",
    "for i in classes:\n",
    "    print(\"Unique values of\", i, ':', data_train[i].unique())\n",
    "\n",
    "temp_train = pd.get_dummies(data_train, columns=classes)\n",
    "temp_test = pd.get_dummies(data_test, columns=classes)\n",
    "le = LabelEncoder()\n",
    "temp_train['class'] = le.fit_transform(temp_train['class']) \n",
    "temp_test['class'] = le.fit_transform(temp_test['class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3543bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd5bbf",
   "metadata": {},
   "source": [
    "# 1) Standardizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eef2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = temp_train.drop('class', axis=1)\n",
    "X_train[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_train[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_train = temp_train['class']\n",
    "X_test = temp_test.drop('class', axis=1)\n",
    "X_test[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_test[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_test = temp_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe5bd0",
   "metadata": {},
   "source": [
    "# 2) Baseline System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4263945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = X_train.groupby(y_train).mean()\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        distances.append(euclidean(X_test.iloc[i], class_means.iloc[j]))\n",
    "    \n",
    "    y_pred.append(distances.index(min(distances)))\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual E', 'Actual P'], columns=['Predicted E', 'Predicted P'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dedaf",
   "metadata": {},
   "source": [
    "# 3) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ed81b",
   "metadata": {},
   "source": [
    "# a) PCA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9658c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, 92, 10):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca_train = pca.fit_transform(X_train)\n",
    "    X_pca_test = pca.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(X_pca_train, y_train)\n",
    "    y_pred_train = lr.predict(X_pca_train)\n",
    "    y_pred = lr.predict(X_pca_test)\n",
    "    \n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Best decomposition value:\", accuracy_test.index(max(accuracy_test))*10+1)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, 92, 10), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d7116",
   "metadata": {},
   "source": [
    "# b) FDA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = LinearDiscriminantAnalysis(n_components=1)\n",
    "fld.fit(X_train, y_train)\n",
    "\n",
    "X_train_fld = fld.transform(X_train)\n",
    "X_test_fld = fld.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_fld, y_train)\n",
    "y_pred = lr.predict(X_test_fld)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f60f7",
   "metadata": {},
   "source": [
    "# c) UFS feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89566f",
   "metadata": {},
   "source": [
    "### Using chi-squared statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    _, p, _, _ = chi2_contingency(pd.crosstab(X_train.iloc[:, i], y_train))\n",
    "    scores.append(p)\n",
    "\n",
    "feature_scores = sorted(zip(X_train.columns, scores), key=lambda x: x[1])\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, len(feature_scores), 10):\n",
    "    selected_features = [j[0] for j in feature_scores[:i]]\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, 92, 10), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ab7f9",
   "metadata": {},
   "source": [
    "### Using ANOVA F-test statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    class_data = []\n",
    "    for j in range(len(np.unique(X_train.iloc[:, i]))):\n",
    "        class_data.append(y_train[X_train.iloc[:, i] == j])\n",
    "    _, p = f_oneway(*class_data)\n",
    "    scores.append(p)\n",
    "\n",
    "feature_scores = sorted(zip(X_train.columns, scores), key=lambda x: x[1])\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, len(feature_scores), 10):\n",
    "    selected_features = [j[0] for j in feature_scores[:i]]\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, 92, 10), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3796b5a",
   "metadata": {},
   "source": [
    "# d) RFE feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1], 10):\n",
    "    num_features = i\n",
    "    selected_features = []\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        score = []\n",
    "        for col in X_train.columns:\n",
    "            if col not in selected_features:\n",
    "                features = selected_features + [col]\n",
    "                lr.fit(X_train[features], y_train)\n",
    "                score.append(lr.score(X_train[features], y_train))\n",
    "        \n",
    "        selected_feature = X_train.columns[np.argmin(score)]\n",
    "        selected_features.append(selected_feature)\n",
    "    \n",
    "    new_train = X_train[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, 92, 10), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, 92, 10), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0d711",
   "metadata": {},
   "source": [
    "# e) SFE feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c7fd9",
   "metadata": {},
   "source": [
    "This took too much time to compute. mention a bit about this in report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e74ea",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9434d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season', 'class']\n",
    "for i in classes:\n",
    "    print(\"Unique values of\", i, ':', sorted(data_train[i].unique()))\n",
    "\n",
    "le = LabelEncoder() \n",
    "for col in data_train.select_dtypes(include=['object']):\n",
    "    data_train[col] = le.fit_transform(data_train[col])\n",
    "    data_test[col] = le.fit_transform(data_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cb0c9",
   "metadata": {},
   "source": [
    "# 1) Standardizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f338e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = data_train.drop('class', axis=1)\n",
    "X_train[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_train[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_train = data_train['class']\n",
    "X_test = data_test.drop('class', axis=1)\n",
    "X_test[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_test[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_test = data_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b84e90",
   "metadata": {},
   "source": [
    "# 2) Baseline System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = X_train.groupby(y_train).mean()\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        distances.append(euclidean(X_test.iloc[i], class_means.iloc[j]))\n",
    "    \n",
    "    y_pred.append(distances.index(min(distances)))\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe404fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual E', 'Actual P'], columns=['Predicted E', 'Predicted P'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02639b",
   "metadata": {},
   "source": [
    "# 3) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e43396",
   "metadata": {},
   "source": [
    "# a) PCA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8280634",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca_train = pca.fit_transform(X_train)\n",
    "    X_pca_test = pca.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(X_pca_train, y_train)\n",
    "    y_pred_train = lr.predict(X_pca_train)\n",
    "    y_pred = lr.predict(X_pca_test)\n",
    "    \n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Best decomposition value:\", accuracy_test.index(max(accuracy_test))+1)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3436b",
   "metadata": {},
   "source": [
    "# b) FDA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81840daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = LinearDiscriminantAnalysis(n_components=1)\n",
    "fld.fit(X_train, y_train)\n",
    "\n",
    "X_train_fld = fld.transform(X_train)\n",
    "X_test_fld = fld.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_fld, y_train)\n",
    "y_pred = lr.predict(X_test_fld)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c63e9",
   "metadata": {},
   "source": [
    "# c) UFS feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb2034",
   "metadata": {},
   "source": [
    "### Using chi-squared statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437de91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    _, p, _, _ = chi2_contingency(pd.crosstab(X_train.iloc[:, i], y_train))\n",
    "    scores.append(p)\n",
    "\n",
    "feature_scores = sorted(zip(X_train.columns, scores), key=lambda x: x[1])\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, len(feature_scores)+1):\n",
    "    selected_features = [j[0] for j in feature_scores[:i]]\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23432ad9",
   "metadata": {},
   "source": [
    "### Using ANOVA F-test statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fcf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    class_data = []\n",
    "    for j in range(len(np.unique(X_train.iloc[:, i]))):\n",
    "        class_data.append(y_train[X_train.iloc[:, i] == j])\n",
    "    _, p = f_oneway(*class_data)\n",
    "    scores.append(p)\n",
    "\n",
    "feature_scores = sorted(zip(X_train.columns, scores), key=lambda x: x[1])\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, len(feature_scores)+1):\n",
    "    selected_features = [j[0] for j in feature_scores[:i]]\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f08c8",
   "metadata": {},
   "source": [
    "# d) RFE feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58575c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    num_features = i\n",
    "    selected_features = []\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        score = []\n",
    "        for col in X_train.columns:\n",
    "            if col not in selected_features:\n",
    "                features = selected_features + [col]\n",
    "                lr.fit(X_train[features], y_train)\n",
    "                score.append(lr.score(X_train[features], y_train))\n",
    "        \n",
    "        selected_feature = X_train.columns[np.argmin(score)]\n",
    "        selected_features.append(selected_feature)\n",
    "    \n",
    "    new_train = X_train[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
