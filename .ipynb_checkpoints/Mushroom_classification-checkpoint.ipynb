{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23469942",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Mushroom_datasets/mushroom_train.csv')\n",
    "data_test = pd.read_csv('Mushroom_datasets/mushroom_test.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9af22",
   "metadata": {},
   "source": [
    "# Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ab325",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_train.shape[0]\n",
    "N1 = data_train[data_train['class']=='p'].shape[0]\n",
    "N2 = data_train[data_train['class']=='e'].shape[0]\n",
    "N_test = data_test['class'].shape[0]\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(N_test):\n",
    "    if random.random() < N1/N:\n",
    "        y_pred.append('p')\n",
    "    else:\n",
    "        y_pred.append('e')\n",
    "\n",
    "acc = 0\n",
    "for i in range(N_test):\n",
    "    if y_pred[i] == data_test['class'][i]:\n",
    "        acc+=1\n",
    "        \n",
    "print(\"Accuracy of test dataset is\", acc*100/N, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a55695",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = f1_score(data_test['class'], y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51354821",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(data_test['class'], y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual P', 'Actual E'], columns=['Predicted P', 'Predicted E'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca1e4a",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season']\n",
    "for i in classes:\n",
    "    print(\"Unique values of\", i, ':', data_train[i].unique())\n",
    "\n",
    "temp_train = pd.get_dummies(data_train, columns=classes)\n",
    "temp_test = pd.get_dummies(data_test, columns=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe5bd0",
   "metadata": {},
   "source": [
    "# Baseline System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4263945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = temp_train.drop('class', axis=1)\n",
    "y_train = temp_train['class']\n",
    "X_test = temp_test.drop('class', axis=1)\n",
    "y_test = temp_test['class']\n",
    "class_means = X_train.groupby(y_train).mean()\n",
    "    \n",
    "y_pred = []\n",
    "class_labels = class_means.index.values\n",
    "for i in range(len(X_test)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        dist = euclidean(X_test.iloc[i], class_means.iloc[j])\n",
    "        distances.append(dist)\n",
    "    pred_idx = distances.index(min(distances))\n",
    "    pred_label = class_labels[pred_idx]\n",
    "    y_pred.append(pred_label)\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = f1_score(y_test, y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual P', 'Actual E'], columns=['Predicted P', 'Predicted E'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ed81b",
   "metadata": {},
   "source": [
    "# Using PCA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=34)\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "X_pca_test = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9658c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_pca_train, y_train)\n",
    "y_pred = lr.predict(X_pca_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d7116",
   "metadata": {},
   "source": [
    "# Using FDA feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "fld = LinearDiscriminantAnalysis(n_components=1)\n",
    "fld.fit(X_train, y_train)\n",
    "\n",
    "X_train_fld = fld.transform(X_train)\n",
    "X_test_fld = fld.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_fld, y_train)\n",
    "y_pred = lr.predict(X_test_fld)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f60f7",
   "metadata": {},
   "source": [
    "# Using UFS feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_train)\n",
    "y_t = label_encoder.fit_transform(y_test)\n",
    "\n",
    "best_select = SelectKBest(score_func=f_regression, k=60)\n",
    "best_select.fit(X_train, y)\n",
    "\n",
    "best_features = best_select.get_support(indices=True)\n",
    "features = X_train.columns[best_features]\n",
    "new_train = X_train[features]\n",
    "new_test = X_test[features]\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(new_train, y)\n",
    "y_pred = lr.predict(new_test)\n",
    "\n",
    "accuracy = accuracy_score(y_t, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3796b5a",
   "metadata": {},
   "source": [
    "# Using RFE feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bf3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "rfe = RFE(lr, n_features_to_select=50)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[fit.support_]\n",
    "final_model = LogisticRegression(max_iter=10000).fit(X_train[selected_features], y_train)\n",
    "y_pred = final_model.predict(X_test[selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0d711",
   "metadata": {},
   "source": [
    "# Using SFE feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4df6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "sfe = SequentialFeatureSelector(lr, n_features_to_select=1)\n",
    "sfe.fit(X_train, y_train)\n",
    "X_train_trans = sfe.transform(X_train)\n",
    "X_test_trans = sfe.transform(X_test)\n",
    "lr.fit(X_train_trans, y_train)\n",
    "y_pred = lr.predict(X_test_trans)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2ccc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
