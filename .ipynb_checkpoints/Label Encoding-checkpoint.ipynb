{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f33d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, log_loss\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357dd7b",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Mushroom_datasets/mushroom_train.csv')\n",
    "data_test = pd.read_csv('Mushroom_datasets/mushroom_test.csv')\n",
    "final_accuracy = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e20ea",
   "metadata": {},
   "source": [
    "# Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f912f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_train.shape[0]\n",
    "N1 = data_train[data_train['class']=='p'].shape[0]\n",
    "N2 = data_train[data_train['class']=='e'].shape[0]\n",
    "N_test = data_test['class'].shape[0]\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(N_test):\n",
    "    if random.random() < N1/N:\n",
    "        y_pred.append('p')\n",
    "    else:\n",
    "        y_pred.append('e')\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(data_test['class'], y_pred)\n",
    "print(\"Accuracy of test dataset is\", accuracy*100, \"%\")\n",
    "final_accuracy['Trival System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(data_test['class'], y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(data_test['class'], y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual P', 'Actual E'], columns=['Predicted P', 'Predicted E'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cc0e4",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data_train.columns if data_train[col].dtype == 'object']\n",
    "for i in features:\n",
    "    print(\"Unique values of\", i, ':', data_train[i].unique())\n",
    "\n",
    "le = LabelEncoder() \n",
    "for col in data_train.select_dtypes(include=['object']):\n",
    "    data_train[col] = le.fit_transform(data_train[col])\n",
    "    data_test[col] = le.fit_transform(data_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32f56d",
   "metadata": {},
   "source": [
    "### Spliting dataset into train and test set and perfoming standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = data_train.drop('class', axis=1)\n",
    "X_train[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_train[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_train = data_train['class']\n",
    "X_test = data_test.drop('class', axis=1)\n",
    "X_test[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_test[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_test = data_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20950e7b",
   "metadata": {},
   "source": [
    "# Baseline System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30080973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = X_train.groupby(y_train).mean()\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        distances.append(euclidean(X_test.iloc[i], class_means.iloc[j]))\n",
    "    \n",
    "    y_pred.append(distances.index(min(distances)))\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")\n",
    "final_accuracy['Baseline System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aeb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual E', 'Actual P'], columns=['Predicted E', 'Predicted P'])\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confussion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314dc802",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033bb3c",
   "metadata": {},
   "source": [
    "## 1) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca_train = pca.fit_transform(X_train)\n",
    "    X_pca_test = pca.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(X_pca_train, y_train)\n",
    "    y_pred_train = lr.predict(X_pca_train)\n",
    "    y_pred = lr.predict(X_pca_test)\n",
    "    \n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Best decomposition value:\", accuracy_test.index(max(accuracy_test))*10+1)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a315a",
   "metadata": {},
   "source": [
    "## 2) Univariate Feature Selection (ANOVA F-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    class_data = []\n",
    "    \n",
    "    for j in range(len(np.unique(X_train.iloc[:, i]))):\n",
    "        class_data.append(y_train[X_train.iloc[:, i]==j])\n",
    "        \n",
    "    _, p = f_oneway(*class_data)\n",
    "    scores.append(p)\n",
    "\n",
    "feature_scores = sorted(zip(X_train.columns, scores), key=lambda x: x[1])\n",
    "\n",
    "UFS_accuracy_train = []\n",
    "UFS_accuracy_test = []\n",
    "UFS_features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    selected_features = [j[0] for j in feature_scores[:i]]\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    UFS_features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    UFS_accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    UFS_accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(UFS_accuracy_test)*100, \"%\")\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(UFS_accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(UFS_accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4ebf6",
   "metadata": {},
   "source": [
    "## 3) Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    num_features = i\n",
    "    selected_features = []\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        score = []\n",
    "        for col in X_train.columns:\n",
    "            if col not in selected_features:\n",
    "                features = selected_features + [col]\n",
    "                lr.fit(X_train[features], y_train)\n",
    "                score.append(lr.score(X_train[features], y_train))\n",
    "        \n",
    "        selected_feature = X_train.columns[np.argmin(score)]\n",
    "        selected_features.append(selected_feature)\n",
    "    \n",
    "    new_train = X_train[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), np.array(accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_train, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1]+1), log_loss_test, label='Test dataset')\n",
    "plt.xlabel(\"Number of feature reductions\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38785af4",
   "metadata": {},
   "source": [
    "# Models with cross validation (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))]\n",
    "splits = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14f9e4",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    lr = LogisticRegression(max_iter = 10000).fit(train_x, train_y)\n",
    "    predict_train = lr.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = lr.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = lr\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['LR'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['LR'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af8c34",
   "metadata": {},
   "source": [
    "## 2) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=0.5, gamma = 3).fit(train_x, train_y)\n",
    "    predict_train = svm.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = svm.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = svm\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Support Vector Machine\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['SVM'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['SVM'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48518430",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    nb = GaussianNB().fit(train_x, train_y)\n",
    "    predict_train = nb.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = nb.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = nb\n",
    "\n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Naive Bayes\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Naive Bayes'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Naive Bayes'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424c769",
   "metadata": {},
   "source": [
    "## 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(train_x, train_y)\n",
    "    predict_train = rf.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = rf.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = rf\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Random Forest'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Random Forest'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61392b",
   "metadata": {},
   "source": [
    "## 5) XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62574a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dval = xgb.DMatrix(val_x, label=val_y)\n",
    "    params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'eta': 0.1, 'gamma': 1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "    num_rounds = 100\n",
    "    \n",
    "    xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "    y_pred_train = xgb_model.predict(dtrain)\n",
    "    y_pred_train_binary = [round(y) for y in y_pred_train]\n",
    "    train_accuracy.append(accuracy_score(y_pred_train_binary, train_y))\n",
    "    \n",
    "    y_pred_test = xgb_model.predict(dval)\n",
    "    y_pred_test_binary = [round(y) for y in y_pred_test]\n",
    "    val_accuracy.append(accuracy_score(y_pred_test_binary, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = xgb_model\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"XgBoost\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2486b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "predict = update.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "final_accuracy['XgBoost'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['XgBoost'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b75b4f",
   "metadata": {},
   "source": [
    "## 6) Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate_init=0.001, max_iter=200, early_stopping=False)\n",
    "    \n",
    "    mlp.fit(train_x, train_y)\n",
    "    predict_train = mlp.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = mlp.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = mlp\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Multi Layer Perceptron\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['MLP'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['MLP'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f5595",
   "metadata": {},
   "source": [
    "## 7) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    adaboost_model = AdaBoostClassifier(n_estimators=50, base_estimator=DecisionTreeClassifier(max_depth=1)).fit(train_x, train_y)\n",
    "    predict_train = adaboost_model.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train,train_y))\n",
    "    \n",
    "    predict_val = adaboost_model.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val,val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = adaboost_model\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"AdaBoost\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['AdaBoost'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['AdaBoost'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf90493",
   "metadata": {},
   "source": [
    "# Final accuracies for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = list(final_accuracy.keys())\n",
    "models = list(final_accuracy.values())\n",
    "plt.bar(accuracy, models)\n",
    "plt.title(\"Model Accuracies for Label Encoding Feature Engineering\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1632e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(final_accuracy, key=final_accuracy.get)\n",
    "best_accuracy = final_accuracy[best_model]\n",
    "print(\"Best model is {best_model} with accuracy {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
